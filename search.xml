<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ShardingSphere</title>
      <link href="/2019/11/28/shardingsphere/"/>
      <url>/2019/11/28/shardingsphere/</url>
      
        <content type="html"><![CDATA[<h1 id="ShardingSphere和PostgreSQL扫盲"><a href="#ShardingSphere和PostgreSQL扫盲" class="headerlink" title="ShardingSphere和PostgreSQL扫盲"></a>ShardingSphere和PostgreSQL扫盲</h1>]]></content>
      
      
      <categories>
          
          <category> ShardingSphere </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ShardingSphere </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zookeeper</title>
      <link href="/2019/09/22/zookeeper/"/>
      <url>/2019/09/22/zookeeper/</url>
      
        <content type="html"><![CDATA[<h3 id="zookeeper配置文件详解"><a href="#zookeeper配置文件详解" class="headerlink" title="zookeeper配置文件详解"></a>zookeeper配置文件详解</h3><pre><code class="shell"># The number of milliseconds of each tick# tick 滴答，可以理解为心跳，为时间单位，initLimit和syncLimit均使用的次单位tickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgement# fowller和leader之间的心跳是5tick,即leader和fowller发送消息，request和response的最长时间syncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.# dataLogDir如果没提供的话使用的则是dataDir。zookeeper的持久化都存储在这两个目录里。# dataLogDir里是放到的顺序日志(WAL)。而dataDir里放的是内存数据结构的snapshot，便于快速恢复。# 为了达到性能最大化，一般建议把dataDir和dataLogDir分到不同的磁盘上，这样就可以充分利用磁盘顺序写的特性。dataLogDir=/usr/local/zookeeper/logsdataDir=/usr/local/zookeeper/data# the port at which the clients will connect 一个TCP端口clientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients# 对于一个客户端的连接数限制，默认是60，这在大部分时候是足够了。但是在我们实际使用中发现，在测试环境经常超过这个数，经过调查发现有的团队将几十个应用全部部署到一台机器上，以方便测试，于是这个数字就超过了#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.#  一般，客户端连接zookeeper的时候，都会设置一个session timeout，如果超过这个时间client没有与zookeeper server有联系，则这个session会被设置为过期(如果这个session上有临时节点，则会被全部删除，这就是实现集群感知的基础，后面的文章会介绍这一点)。但是这个时间不是客户端可以无限制设置的，服务器可以设置这两个参数来限制客户端设置的范围## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir# autopurge.snapRetainCount，autopurge.purgeInterval -- 客户端在与zookeeper交互过程中会产生非常多的日志，而且zookeeper也会将内存中的数据作为snapshot保存下来，这些数据是不会被自动删除的，这样磁盘中这样的数据就会越来越多。不过可以通过这两个参数来设置，让zookeeper自动删除数据。autopurge.purgeInterval就是设置多少小时清理一次。而autopurge.snapRetainCount是设置保留多少个snapshot，之前的则删除。# 不过如果你的集群是一个非常繁忙的集群，然后又碰上这个删除操作，可能会影响zookeeper集群的性能，所以一般会让这个过程在访问低谷的时候进行，但是遗憾的是zookeeper并没有设置在哪个时间点运行的设置，所以有的时候我们会禁用这个自动删除的功能，而在服务器上配置一个cron，然后在凌晨来干这件事#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1server.1= 192.168.1.131:2888:3888server.2= 192.168.1.132:2888:3888server.3= 192.168.1.133:2888:3888</code></pre>]]></content>
      
      
      <categories>
          
          <category> zookeeper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux环境配置</title>
      <link href="/2019/08/18/linux-env/"/>
      <url>/2019/08/18/linux-env/</url>
      
        <content type="html"><![CDATA[<h3 id="安装jdk"><a href="#安装jdk" class="headerlink" title="安装jdk"></a>安装jdk</h3><p>下载jdk的rpm文件<code>jdk-8u221-linux-i586.rpm</code></p><pre><code class="shell">## 安装JDKrpm -ivh jdk-8u221-linux-i586.rpm## 修改文件夹名称cd /usr/java/mv jdk1.8.0_221-i586/ jdk1.8## 配置jdk的环境变量cd /usr/local/vi .bashrc## 修改环境变量配置export JAVA_HOME=/usr/java/jdk1.8export PATH=$PATH:$JAVA_HOME/bin## 刷新配置source .bashrc## 验证是否安装成功java -version</code></pre>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> linux环境配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka安装</title>
      <link href="/2019/08/18/kafka-install/"/>
      <url>/2019/08/18/kafka-install/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h2 id="MAC环境下安装kafka"><a href="#MAC环境下安装kafka" class="headerlink" title="MAC环境下安装kafka"></a>MAC环境下安装kafka</h2><p>MAC环境下我们使用Homebrew安装kafka</p><p>如果没有安装homebrew的话，请自行google安装。鉴于伟大的GFW的存在，homebrew安装完成了推荐设置下国内镜像源加速。</p><p>安装kafka前请先安装jdk环境，推荐jdk8以上的版本</p><h3 id="homebrew安装kafka命令"><a href="#homebrew安装kafka命令" class="headerlink" title="homebrew安装kafka命令"></a>homebrew安装kafka命令</h3><pre><code class="shell">brew install kafka</code></pre><p>done</p><p>kafka使用zookeeper保存kafka集群的的<code>metadata</code>和<code>consumer client details</code>，所以，安装kafka前需要安装zookeeper</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g63q55xm3fj31480fuwgy.jpg" alt="zk cluster"></p><h3 id="homebrew安装kafka后的文件地址"><a href="#homebrew安装kafka后的文件地址" class="headerlink" title="homebrew安装kafka后的文件地址"></a>homebrew安装kafka后的文件地址</h3><p>homebrew将安装的kafka和zookeeper放在<code>/usr/local/Cellar</code>目录下</p><p>本次安装的kafka的版本为<code>2.2.0</code>，zookeeper版本为<code>3.4.13</code></p><ul><li>homebrew将kafka和zookeeper的一些二进制文件和脚本文件的链接放在了<code>/usr/local/bin</code>目录下，比如说zk的<code>zkServer</code>、<code>zkCli</code>以及kafka的<code>kafka-server-start</code>、<code>kafka-server-stop</code>等脚本。</li><li>kafka和zk的配置文件分别在<code>/usr/local/etc/kafka</code>和<code>/usr/local/etc/zookeeper</code>中。</li><li>kafka和zk的的log目录分别在<code>/usr/local/var/log/kafka</code>和<code>/usr/local/var/log/zookeeper</code>中。</li></ul><h3 id="启动zk"><a href="#启动zk" class="headerlink" title="启动zk"></a>启动zk</h3><pre><code class="shell"># 启动zkzkServer start# 查看zk是否启动zkServer status# 或者查看zk的端口号lsof -i:2181lsof -i tcp:2181</code></pre><p>查看zk状态</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g63piufl85j30l204wjs3.jpg" alt="zkServer status"></p><p>查看端口号</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g63q6yo4pjj30w208igol.jpg" alt="port"></p><h3 id="启动kafka"><a href="#启动kafka" class="headerlink" title="启动kafka"></a>启动kafka</h3><pre><code class="shell"># 前台启动kafkakafka-server-start /usr/local/etc/kafka/server.properties# 查看是否启动，基于查看端口号lsof -i:9092# 后台启动kafkakafka-server-start -daemon /usr/local/etc/kafka/server.properties</code></pre><h3 id="创建主题"><a href="#创建主题" class="headerlink" title="创建主题"></a>创建主题</h3><pre><code class="shell">kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test# 显示主题列表kafka-topics --list --bootstrap-server localhost:9092# 删除主题kafka-topics --delete --bootstrap-server localhost:9092 --topic test</code></pre><h3 id="发送消息"><a href="#发送消息" class="headerlink" title="发送消息"></a>发送消息</h3><pre><code class="shell"># 发送kafka消息kafka-console-producer --broker-list localhost:9092 --topic test# start a listenerkafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning</code></pre><h2 id="LINUX环境下安装kafka"><a href="#LINUX环境下安装kafka" class="headerlink" title="LINUX环境下安装kafka"></a>LINUX环境下安装kafka</h2><p>linux环境下安装kafka和zookeeper版本和mac版本保持一致，kafka为2.2.0,zk的版本为<code>3.4.13</code>，zk对应的<code>tar.gz</code>文件推荐去官网中下载，不要去github中下载，github中的<code>tar.gz</code>文件可能安装不成功。</p><p><a href="http://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/" target="_blank" rel="noopener">zk下载地址</a></p><p><a href="https://github.com/apache/kafka/releases" target="_blank" rel="noopener">kafka下载地址</a></p><p>首先要在linux机器中安装java8以上的jdk环境。</p><h3 id="单机版"><a href="#单机版" class="headerlink" title="单机版"></a>单机版</h3>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> kafka安装 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/08/15/hello-world/"/>
      <url>/2019/08/15/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
